---
layout: single
permalink: /
author_profile: true
toc: false
classes: wide pr
---

I am interested in Bayesian statistics and machine learning, in particular I have been exploring Bayesian surrogates, Bayesian optimization and amortized likelihood-free inference.

For instance, while there has been work towards the design of black-box inference methods, bespoke solutions can exploit additional information to increase sample efficiency.
I have designed and developed a class of [informative priors over functions](/mlprojects/#informative-covariance) that leverage nonstationarity to encode preferences, accelerating optimization and inference even under weak prior information.

Relatedly, I have also proposed a [new active sampling method](/mlprojects/#mode-collapsed-acquisition-functions) that leads to more informative samples compared to the traditional acquisition methods used in Bayesian optimization. The method is based on the idea of sequential Laplace approximation, or sequential mode-seeking variational inference, with mode collapse.

<span style="font-size:25px">**Education**</span>

**MSc in Artificial Intelligence**, University of Edinburgh, best student (Howe Masters Prize), 2018.<br>
*Specialization: Bayesian Statistics and Machine Learning.*
 
**MSc in Electrical & Computer Engineering**, Instituto Superior TÃ©cnico, University of Lisbon, top 1%, 2015.<br>
*Specialization: Signal Processing, Telecommunications and Embedded Systems.*