---
layout: single
permalink: /
author_profile: true
toc: false
classes: wide pr
---

I am interested in Bayesian statistics and machine learning, having focused on Bayesian optimization with Gaussian process surrogates and amortized likelihood-free inference.

For instance, while there has been a push to develop more black-box methods, bespoke approaches can exploit additional information to increase sample efficiency. As part of my PhD research, I have designed and developed a class of [informative priors over functions](/mlprojects/#informative-covariance) that leverage nonstationarity to encode preferences, accelerating optimization and inference even under weak prior information.

I have also proposed a [new active sampling method](/mlprojects/#mode-collapsed-acquisition-functions) that leads to more informative samples compared to the traditional acquisition methods used in Bayesian optimization. This method is based on the concept of sequential Laplace approximation, or sequential mode-seeking variational inference, with mode collapse.



<span style="font-size:25px">**Education**</span>

**MSc in Artificial Intelligence**, University of Edinburgh, best student (Howe Masters Prize), 2018.<br>
*Specialization: Bayesian Statistics and Machine Learning.*
 
**MSc in Electrical & Computer Engineering**, Instituto Superior TÃ©cnico, University of Lisbon, top 1%, 2015.<br>
*Specialization: Signal Processing, Telecommunications and Embedded Systems.*